{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JQKsH8DRm6H"
   },
   "source": [
    "# Serving Models\n",
    "\n",
    "This notebook contains a PyTorch model trained on the Iris dataset.  We will be using this model throughout the remainder of the model serving material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsXt1MZV9QRx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, shutil\n",
    "if not '_nbdir_' in globals(): \n",
    "  _nbdir_ = os.getcwd()\n",
    "os.chdir(_nbdir_+'/..')\n",
    "\n",
    "model_path = 'models/texrank'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQD1elZA_r8x"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s3vzh38jLWn4",
    "outputId": "941ca9e0-1c84-453e-c821-e65eaa235b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for $ 89 , self-styled entrepreneur kyle waring will ship you 6 pounds of boston-area snow in an insulated styrofoam box -- enough for 10 to 15 snowballs , he says . so this week , waring began shipping larger amounts in the styrofoam cubes , which he promises will arrive anywhere in the u.s. in less than 20 hours . many of his customers appear to be companies in warm-weather states who are buying the snow as a gag , he said .\n"
     ]
    }
   ],
   "source": [
    "from datasets import CNNDailyMail\n",
    "import summa.summarizer as TextRank\n",
    "\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "example = CNNDailyMail(split='val', verbose=False)[0].src\n",
    "model = lambda text: TextRank.summarize(text, words=50)\n",
    "\n",
    "def predict(text, sentences=3):\n",
    "  parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "  summarizer = TextRankSummarizer()\n",
    "  summary = summarizer(parser.document, sentences)\n",
    "  summary = ' '.join(map(str, summary))\n",
    "  return summary\n",
    "\n",
    "print(predict(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocxz89Z3RaVf"
   },
   "source": [
    "# MLflow PyFunc Packaging\n",
    "\n",
    "Now that we have everything serialized to disk it's time to package everything up together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hn_DCm6Bdr4m"
   },
   "outputs": [],
   "source": [
    "# This will serve as an MLflow wrapper for the model\n",
    "class ModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "  # Load in the model and all required artifacts\n",
    "  # The context object is provided by the MLflow framework\n",
    "  # It will contain all of the artifacts specified above\n",
    "  def load_context(self, context):\n",
    "    from models import TextRank\n",
    "    self.model = TextRank()\n",
    "    \n",
    "  # Create a predict function for our models\n",
    "  def predict(self, context, model_input):\n",
    "    preds = []\n",
    "    for row in model_input.iloc:\n",
    "      preds.append(self.model(row['text'], row['mode'], int(row['length'])))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "mijZDTgcdzPE",
    "outputId": "6f72290f-d608-416e-acfc-75a39cd593e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mlflow-env',\n",
       " 'channels': ['defaults'],\n",
       " 'dependencies': ['python=3.8.1', {'pip': ['mlflow', 'cloudpickle==1.3.0']}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the default conda environment for MLflow\n",
    "mlflow.pyfunc.get_default_conda_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRaLoPw1ayt4"
   },
   "outputs": [],
   "source": [
    "import sumy\n",
    "\n",
    "# Let's create our own conda environment\n",
    "conda_env = {\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "      'python=3.6.9',\n",
    "      {\n",
    "        'pip':[\n",
    "          f'mlflow=={mlflow.__version__}',\n",
    "          f'summa==1.2.0',\n",
    "          f'sumy=={sumy.__version__}',\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    'name': 'mlflow-env-textrank'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cok2toOTdr4p"
   },
   "outputs": [],
   "source": [
    "# Package the model!\n",
    "if os.path.isdir(model_path):  shutil.rmtree(model_path)\n",
    "\n",
    "mlflow.pyfunc.save_model(path=model_path,\n",
    "                         python_model=ModelWrapper(),\n",
    "                         conda_env=conda_env,\n",
    "                         artifacts={'example': 'assets/example.txt'},\n",
    "                         code_path=['models.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EacwpPb4Vxt5"
   },
   "source": [
    "# Test Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZyYwS-H-dr4y",
    "outputId": "7c19d9a7-6f71-41fe-d90f-d63dddd165bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Health officials are also tracing the steps of care workers at the centre to ensure the virus hasn't spread to other parts of the community. She said the centre has done a good job letting family members know about the infections and steps it's taking to prevent the virus from spreading. Provincial efforts ramped up On Friday the province announced plans to ramp up its response to the coronavirus outbreak, outlining a wide-ranging provincial pandemic co-ordination plan to contain the spread of the COVID-19, the disease that results from the virus.\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the model in `python_function` format\n",
    "loaded_model = mlflow.pyfunc.load_model(model_path)\n",
    "\n",
    "# Evaluate the model\n",
    "with open(model_path+'/artifacts/example.txt', 'r') as f:\n",
    "  example = f.read()\n",
    "example = {'text': [example], 'mode': ['sentences'], 'length': [3]}\n",
    "example = pd.DataFrame(example)\n",
    "test_predictions = loaded_model.predict(example)\n",
    "\n",
    "print(test_predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "iris_example_hands_on_FINISHED.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
