{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get CNN/DailyMail dataset from GitHub repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pprint, re\n",
    "from datetime import datetime\n",
    "\n",
    "if not 'workbookDir' in globals():  workbookDir = os.getcwd()\n",
    "os.chdir(workbookDir+'/..')\n",
    "  \n",
    "try:    __set_jtplot__('dark')\n",
    "except: pass\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing data.\n",
      "287227 documents.\n"
     ]
    }
   ],
   "source": [
    "%run datasets.py\n",
    "ds = CNNDailyMail(split='train')  # train, val, or test\n",
    "print(f'{len(ds)} documents.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LexRank model\n",
    "The LexRank model finds the most significant sentences from a passage.\n",
    "\n",
    "**Training time (Yenson's laptop):**\n",
    "  - 500  segments: ~13s\n",
    "  - 1000 segments: ~30s\n",
    "  - 2000 segments: ~60s\n",
    "  - 4000 segments: ~130s\n",
    "\n",
    "Looks roughly linear (maybe nlog(n)?) -- won't know for sure at limited scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model took 15s.\n"
     ]
    }
   ],
   "source": [
    "from lexrank import STOPWORDS, LexRank\n",
    "\n",
    "trainSegs = min(500, len(ds))\n",
    "\n",
    "ds.outFilt = lambda out: out.src  # use sources only\n",
    "startTime = datetime.now()\n",
    "lxr = LexRank(ds[:trainSegs], stopwords=STOPWORDS['en'])\n",
    "print(f'Creating model took {(datetime.now()-startTime).seconds}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test segment has 41 sentences.\n",
      "\n",
      "Test segment has 41 sentences. Printing 5:\n",
      "[ \"A facebook page seeking to preserve the ` black pete ' clowns in blackface \"\n",
      "  'who accompany st.',\n",
      "  'Nicholas to the netherlands during the holidays has become the '\n",
      "  \"fastest-growing dutch-language page ever, receiving 1 million ` likes ' in \"\n",
      "  'a single day.',\n",
      "  \"The popularity of the ` pete-ition ' page reflects the emotional attachment \"\n",
      "  'most dutch have to a figure that helped launch the tradition of santa '\n",
      "  'claus.',\n",
      "  'It also reflects their anger at critics who call it racist.',\n",
      "  \"Those critics include foreigners who they feel do n't understand the \"\n",
      "  'tradition.']\n"
     ]
    }
   ],
   "source": [
    "ds.outFilt = None    # get source and target\n",
    "\n",
    "def to_sentences(seg):\n",
    "  sentences = map(lambda sent: sent.strip(), seg.split('.'))\n",
    "  sentences = filter(lambda sent: len(sent)>0, sentences)\n",
    "  sentences = map(lambda sent: re.sub(r' , ', ', ', sent), sentences)\n",
    "  sentences = map(lambda sent: sent[0].upper()+sent[1:]+'.', sentences)\n",
    "  return list(sentences)\n",
    "\n",
    "\n",
    "testSeg = ds[-1]\n",
    "testSents = to_sentences(testSeg.src)\n",
    "print(f'Test segment has {len(testSents)} sentences.\\n')\n",
    "\n",
    "testSeg = ds[-1]\n",
    "testSents = to_sentences(testSeg.src)\n",
    "print(f'Test segment has {len(testSents)} sentences. Printing 5:')\n",
    "pp.pprint(testSents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test summary of 2 sentences:\n",
      "[ 'Controversial : many claim that the tradition is offensive towards black '\n",
      "  'people.',\n",
      "  'Opponents say pete is an offensive caricature of black people.']\n"
     ]
    }
   ],
   "source": [
    "summary_size = 2\n",
    "summary = lxr.get_summary(testSents, summary_size=summary_size, threshold=.1)\n",
    "print(f'Test summary of {summary_size} sentences:')\n",
    "pp.pprint(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target summary:\n",
      "[ \"Facebook page supporting tradition gains one million ` likes ' in a day.\",\n",
      "  \"` do n't let the netherlands ' most beautiful tradition disappear, ' it \"\n",
      "  'says.',\n",
      "  'Un has condemned the tradition claiming it reflects racial prejudice.']\n"
     ]
    }
   ],
   "source": [
    "tgt = to_sentences(' '.join(ds.split_tags(testSeg.tgt)))\n",
    "print('Target summary:')\n",
    "pp.pprint(tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the ROUGE metric to evaluate performance\n",
    "Choose one of the F1 (`'f'`) scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'rouge-1': { 'f': 0.06779660549267486,\n",
      "                 'p': 0.09090909090909091,\n",
      "                 'r': 0.05405405405405406},\n",
      "    'rouge-2': { 'f': 0.03508771464450662,\n",
      "                 'p': 0.047619047619047616,\n",
      "                 'r': 0.027777777777777776},\n",
      "    'rouge-l': { 'f': 0.08333332864583361,\n",
      "                 'p': 0.1111111111111111,\n",
      "                 'r': 0.06666666666666667}}]\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(' '.join(summary), ' '.join(tgt))\n",
    "pp.pprint(scores)  # choose one of the F1 (f) scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
