{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JQKsH8DRm6H"
   },
   "source": [
    "# Serving Models\n",
    "\n",
    "This notebook contains a PyTorch model trained on the Iris dataset.  We will be using this model throughout the remainder of the model serving material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsXt1MZV9QRx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import os, shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model_path = 'data/iris_model/'\n",
    "if os.path.isdir('data'):  shutil.rmtree('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfRBsUug-fpu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-16 18:48:14--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.124.133\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.124.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3975 (3.9K) [text/plain]\n",
      "Saving to: ‘data/iris.csv’\n",
      "\n",
      "iris.csv            100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-16 18:48:14 (52.6 MB/s) - ‘data/iris.csv’ saved [3975/3975]\n",
      "\n",
      "iris.csv\n"
     ]
    }
   ],
   "source": [
    "# Download the csv to the content directory in colab\n",
    "# You can see the csv by opening the file explorer tab on the left of the screen\n",
    "# You may need to click the refresh button at the top of the file explorer window\n",
    "! wget -P data -nc https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
    "! ls data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQ_prRPT_v2u"
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOLFYwNJjkDL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the csv into a pandas dataframe and inspect the data\n",
    "iris_df = pd.read_csv('data/iris.csv')\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wbyEJLCGjLy7"
   },
   "outputs": [],
   "source": [
    "# Initialize a label encoder for the class names\n",
    "# This is an example of a data artifact that will be required at inference time\n",
    "# Any data preprocessing artifacts should be packaged with the corresponding model\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# Convert labels to ints\n",
    "iris_df['variety'] = label_encoder.fit_transform(iris_df['variety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGEWO_9Yx-Ym"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: variety, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label breakdown - we no longer have strings for class names\n",
    "iris_df['variety'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25gsnahH_J76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the data after label encoding\n",
    "print(iris_df.shape)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMJHpdyl_mZq"
   },
   "outputs": [],
   "source": [
    "# Drop labels from out training features\n",
    "iris_x = iris_df.drop('variety', axis = 1)\n",
    "iris_y = iris_df[['variety']]\n",
    "\n",
    "# Generate train / test splits for training and evaluation\n",
    "X_train, x_test, Y_train, y_test = train_test_split(iris_x,\n",
    "                                                    iris_y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4s-pZfR_-CD"
   },
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train = torch.from_numpy(X_train.values).float()\n",
    "X_test = torch.from_numpy(x_test.values).float()\n",
    "y_train = torch.from_numpy(Y_train.values).view(1,-1)[0]\n",
    "y_test = torch.from_numpy(y_test.values).view(1,-1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQD1elZA_r8x"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxnqjdLVUnoS"
   },
   "source": [
    "Models are typically created within a notebook but the model class should be separated out into its own Python file for packaging purposes.  Notebooks are great for experimenting with ideas but it can be a challenge to then take that code and structure it properly in a project format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNHE-rlk9Zpo"
   },
   "outputs": [],
   "source": [
    "# PLEASE WATCH THE ACCOMPANYING VIDEO FOR THIS NOTEBOOK\n",
    "# NOTE: REMEBER IN THE VIDEO WE SEPERATED OUT OUR MODEL CLASS\n",
    "# INTO ITS OWN MODEL.PY FILE\n",
    "\n",
    "# We will eventually pull this model out into its own Python file for packaging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "input_size = 4\n",
    "output_size = 3\n",
    "hidden_size = 30\n",
    "\n",
    "class IrisNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = torch.sigmoid((self.fc1(X)))\n",
    "        X = torch.sigmoid(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return F.log_softmax(X, dim=-1)\n",
    "\n",
    "\n",
    "# Since we move our model class to model.py\n",
    "# We can import it from the local file system\n",
    "# This files is included in the material\n",
    "\n",
    "# from model import IrisNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TITSQdwc9fNQ"
   },
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "model = IrisNet()\n",
    "\n",
    "# Set the optamizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.03)\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxaZAGlTBgpk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 loss: 1.1526415348052979\n",
      "Epoch: 100 loss: 0.025860214605927467\n",
      "Epoch: 200 loss: 0.01853129267692566\n",
      "Epoch: 300 loss: 0.014463581144809723\n",
      "Epoch: 400 loss: 0.015961652621626854\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred , y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch} loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cp6gJ3G4C3Ud"
   },
   "outputs": [],
   "source": [
    "def inference(model, user_input):\n",
    "    \"\"\"\n",
    "    Conduct inference for a model\n",
    "    Args:\n",
    "      model (torch): An instance of a torch model\n",
    "      user_input (tensor): User provided input strucutred as a tensor\n",
    "    Returns:\n",
    "      Predicted labels [(str)]\n",
    "    \"\"\"\n",
    "\n",
    "    # Get prediction\n",
    "    pred = torch.argmax(model(user_input), dim=1)\n",
    "\n",
    "    # Given the predicted integer, find the label from the label encoder\n",
    "    pred_labels = label_encoder.inverse_transform(pred)\n",
    "\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3vzh38jLWn4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Setosa']\n"
     ]
    }
   ],
   "source": [
    "# Take a Setosa sample from X_test\n",
    "example = torch.tensor([[5.1, 3.5, 1.4, 0.2]])\n",
    "\n",
    "# Inference\n",
    "pred = inference(model, example)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6U8MpaEsT9D"
   },
   "source": [
    "# MLflow PyTorch Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24U1bjqPsSSD"
   },
   "outputs": [],
   "source": [
    "import mlflow.pytorch\n",
    "\n",
    "mlflow_pytorch_path = model_path+'mlflow_pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CkF6A5dFsr2N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mlflow-env',\n",
       " 'channels': ['defaults', 'pytorch'],\n",
       " 'dependencies': ['python=3.8.1',\n",
       "  'pytorch=1.4.0',\n",
       "  'torchvision=0.5.0',\n",
       "  {'pip': ['mlflow', 'cloudpickle==1.3.0']}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default Conda ENV\n",
    "mlflow.pytorch.get_default_conda_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vVSlbW9s8dm"
   },
   "outputs": [],
   "source": [
    "# Let's create our own conda environment\n",
    "conda_env = {\n",
    "    'channels': ['defaults', 'pytorch'],\n",
    "    'dependencies': [\n",
    "      f'python=3.6.9',\n",
    "      {\n",
    "          'pip':[\n",
    "            f'mlflow=={mlflow.__version__}',\n",
    "            f'scikit-learn=={sklearn.__version__}',\n",
    "            'torch==1.4.0',\n",
    "            'cloudpickle==1.2.2'\n",
    "          ]\n",
    "      }\n",
    "    ],\n",
    "    'name': 'mlflow-env-iris'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FahaiEXssX76"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "mlflow.pytorch.save_model(model, mlflow_pytorch_path, conda_env=conda_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AgeU-A4wi4W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "new_model = mlflow.pytorch.load_model(mlflow_pytorch_path)\n",
    "\n",
    "# Take a Setosa sample from X_test\n",
    "example = torch.tensor([[5.1, 3.5, 1.4, 0.2]])\n",
    "\n",
    "# Get prediction\n",
    "pred = torch.argmax(new_model(example), dim=1)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRcUdGHdWU80"
   },
   "source": [
    "# Serializing data artifacts\n",
    "\n",
    "We will need to serialize a few data artifacts for this model:\n",
    "\n",
    "\n",
    "\n",
    "1.   Our PyTorch models state_dict\n",
    "2.   The label encoder used for transforming ints to their corresponding strings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihClZRTaWy1H"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ClfBCHPdr4a"
   },
   "outputs": [],
   "source": [
    "# Serialize the label encoder\n",
    "# This will be required at inference time\n",
    "le_path = model_path+'label_encoder.pkl'\n",
    "with open(le_path, 'wb') as handle:\n",
    "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycF5Gruodr4f"
   },
   "outputs": [],
   "source": [
    "# Serialize the models state_dict\n",
    "state_dict_path = model_path+f'state_dict.pt'\n",
    "\n",
    "### TODO 1: save the models state_dict to the path above\n",
    "torch.save(model.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_kh1C3MXiI1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_dict.pt', 'mlflow_pytorch', 'label_encoder.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the data artifacts\n",
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocxz89Z3RaVf"
   },
   "source": [
    "# MLflow PyFunc Packaging\n",
    "\n",
    "Now that we have everything serialized to disk it's time to package everything up together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hn_DCm6Bdr4m"
   },
   "outputs": [],
   "source": [
    "# Here we will create an artifacts object\n",
    "# It will contain all of the data artifacts that we want to package with the model\n",
    "artifacts = {\n",
    "  \"state_dict\": state_dict_path,\n",
    "  ### TODO 3: We need to serialize more than just the state_dict \n",
    "  \"label_encoder\": le_path\n",
    "}\n",
    "\n",
    "\n",
    "# This will serve as an MLflow wrapper for the model\n",
    "class ModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    # Load in the model and all required artifacts\n",
    "    # The context object is provided by the MLflow framework\n",
    "    # It will contain all of the artifacts specified above\n",
    "    def load_context(self, context):\n",
    "        import torch\n",
    "        import pickle\n",
    "        from model import IrisNet\n",
    "\n",
    "        # Initialize the model and load in the state dict\n",
    "        self.model = IrisNet() ### TODO 4: We need to instantiate out=r model\n",
    "        ### TODO 5: What do we want to load into our model?\n",
    "        self.model.load_state_dict(torch.load(context.artifacts['state_dict']))\n",
    "\n",
    "        # Load in and deserialize the label encoder object\n",
    "        with open(context.artifacts[\"label_encoder\"], 'rb') as handle:\n",
    "            self.label_encoder = pickle.load(handle)\n",
    "\n",
    "    # Create a predict function for our models\n",
    "    def predict(self, context, model_input):\n",
    "      \n",
    "        example = torch.tensor(model_input.values)\n",
    "        pred = torch.argmax(model(example.float()), dim=1)\n",
    "        pred_labels = self.label_encoder.inverse_transform(pred)\n",
    "        return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mijZDTgcdzPE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mlflow-env',\n",
       " 'channels': ['defaults'],\n",
       " 'dependencies': ['python=3.8.1', {'pip': ['mlflow', 'cloudpickle==1.3.0']}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the default conda environment for MLflow\n",
    "mlflow.pyfunc.get_default_conda_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRaLoPw1ayt4"
   },
   "outputs": [],
   "source": [
    "# PLEASE NOTE: I HAVE CHANGED THE DICT STRUCTURE SLIGHTY FROM THE VIDEO\n",
    "\n",
    "# Let's create our own conda environment\n",
    "conda_env = {\n",
    "    'channels': ['defaults', 'pytorch'],\n",
    "    'dependencies': [\n",
    "      f'python=3.6.9',\n",
    "      {\n",
    "          'pip':[\n",
    "            f'mlflow=={mlflow.__version__}',\n",
    "            f'scikit-learn=={sklearn.__version__}',\n",
    "            'torch==1.4.0',\n",
    "            'cloudpickle==1.2.2'\n",
    "          ]\n",
    "      }\n",
    "    ],\n",
    "    'name': 'mlflow-env-iris'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cok2toOTdr4p"
   },
   "outputs": [],
   "source": [
    "# Location in our gdrive where we want the model to be saved\n",
    "mlflow_pyfunc_model_path = model_path+f\"model_pyfunc\"\n",
    "if os.path.isdir(mlflow_pyfunc_model_path):\n",
    "  shutil.rmtree(mlflow_pyfunc_model_path)\n",
    "\n",
    "# Package the model!\n",
    "mlflow.pyfunc.save_model(path=mlflow_pyfunc_model_path,\n",
    "                         python_model=ModelWrapper(),\n",
    "                         artifacts=artifacts,\n",
    "                         conda_env=conda_env,\n",
    "                         ### TODO 6: What other code file do we want to save here? \n",
    "                         code_path=['model.py', 'meta_data.txt']\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_pyfunc', 'state_dict.pt', 'mlflow_pytorch', 'label_encoder.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EacwpPb4Vxt5"
   },
   "source": [
    "# Test Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyYwS-H-dr4y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Setosa']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the model in `python_function` format\n",
    "loaded_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)\n",
    "\n",
    "test_input = pd.DataFrame([[5.1, 3.5, 1.4, 0.2]])\n",
    "\n",
    "# Evaluate the model\n",
    "### TODO 7: Let's make a prediction on our test_input\n",
    "test_predictions = loaded_model.predict(test_input)\n",
    "\n",
    "print(test_predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "iris_example_hands_on.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
